
---
title: 5- Adobe UX Foundation Journey NASSCOM
date: "2021-08-07T23:46:37.121Z"
description: "This is a NAASCOM initiative course with ADOBE. This Adobe course "
---


# AI -ML-DEEP LEARNING

### Medium Blog-  https://medium.com/@suhas100809/ai-ml-deep-learning-b93851558d02

Web apps have grown increasingly social and interactive over the last few years, with multimedia, comments, information and other features all occurring in real-time by tens of thousands of users on even a moderately successful website. But this has increased the chance for spammers to take advantage of this system by associating less savoury information with articles, posts, videos etc created by others to obtain more attention towards themselves. We have noticed in various Youtube videos, public Instagram and Facebook posts, that these spammers advertise their products by posting vague comments.

Older spam detection measures, such as a list of blocked words or prohibited terms, may simply be overcome, and advanced spam bots, which are constantly developing in their sophistication, are simply no match for them. But today, we can now use Machine Learning models that have been trained with a large amount of these types of data to detect such spam.

Previously, running a Machine Learning model to pre-filter comments or spams was done on the server-side, but with TensorFlow.js, we can now run machine learning models client-side in-browser through JavaScript before such comments even reach the backend, possibly saving server resources too.

Machine Learning, as we may be aware, is quite the buzzword these days, affecting virtually every sector, but how can we begin to leverage these skills as web developers?
We will use Natural language processing (NLP), which is the art of interpreting human language by a computer, to understand how to create a web app from scratch that addresses the very real problem of comment spam that many web developers will face. 

First, let’s review what Machine learning is, where Tensorflow.js fits in, and why we’ll utilise it with Javascript. We have heard a lot of concepts in this field i.e AI, deep learning, ML etc. We’ll explore one by one.

## AI-

Artificial intelligence (AI) is the science of making things smarter. Artificial intelligence may be described as human intelligence displayed by machines. However, this is a wide word. Presently, we’re working on systems for the other type of narrow AI. What does this imply?

Narrow AI is a system that can accomplish one or a few things as well as or better than a human specialist at that activity. They are focused on one particular task.
Text classification is an excellent example of this. As a web developer, we may have been requested to create a contact form where the user enters a message, the message is delivered to the firm, and someone chooses which sub-team the message should be passed to. 
Well, with advances in technology, we can now train a system to automatically route the message to the correct team based on its content.


## ML-

Machine learning (ML) is a subset of artificial intelligence (AI) that enables software programmes to grow increasingly effective at predicting outcomes without explicitly programming them to do so. Machine learning algorithms anticipate new output values by using past data as input.
What is it about these machine learning systems that makes them so effective?

The most important thing is that they can be re-trained with new data and reused again and again in various projects without modifying the source code. So let’s take an example, I develop a Machine learning model that detects cats and it was completed successfully. Now if my friends want a model which can detect dogs, they can then use the same code to recognise dogs without making any changes. They just have to provide a variety of dog training pictures, their information from here the ML model can learn from. And this type of technique is really effective and a significant departure from how we previously employed software.

In reality, using spam emails as an example, we may have utilised conditional criteria in the past to determine if a word was linked with spam. We would block or restrict the email if that was the case. Spammers, on the other hand, may get aware of this, slightly alter the term, make few changes and the system is broken.
But now we can address this problem using machine learning.

Instead, thousands of people label emails as spam, and machine learning determines which phrases and attributes are most likely to have contributed to spam emails.
We can then retrain the model with new content every day, and no person is required to update manual lists, freeing up their time to accomplish other things.
And numerous popular machine learning use cases go beyond text as well. Such as object detection to determine what is present in a picture or numerical regressions to forecast an output number based on an input number.

### What would the price of a 2000-square-foot house be, for example?
We can actually predict that if we have enough examples. We can now understand phrases and words thanks to Natural language processing(NLP).
We may use this to determine whether a sentence in a blog post remark is unpleasant, positive, negative, or neutral.
Then there’s audio for things like speech recognition, which is how our smart assistant or phone understands spoken instructions.

![image](https://user-images.githubusercontent.com/58622363/131258374-0183d3b0-62e2-4587-a654-4dcc148c8017.png)
![image](https://user-images.githubusercontent.com/58622363/131258387-22bf27c9-3bb3-41a1-ac97-d53521d813fa.png)

The faces on the left do not exist. In fact, a machine learning program has learned what the essence of a human face maybe and then it’s asked to generate new ones. If you are asked to draw the faces you can draw it too, an unknown face with your imagination as you have seen 1000s of faces till now. The same thing is going on with the model here except the computer’s really good at drawing.

## Deep Learning-

It’s a machine learning implementation approach that we recently learnt about. And this is only one of the numerous algorithms available for making the machine learning software function.
Deep neural networks are simply coded structures that are built in layers and are roughly based on how we believe the human brain functions, essentially learning patterns of patterns.

And what precisely do I mean by that?
Imagine one can distinguish something basic, like a collection of lines, in the early stages; move one level deeper, and those lines may combine to allow us to recognise forms. If we go one level deeper, those forms may combine to allow us to distinguish items. A face, for example, might be represented by several shape characteristics at a certain position relative to each other. And if you go further into the layers, it will be able to recognise more complicated patterns, but it will also take more processing power to do so.
The deep learning algorithm is employed in the machine learning software that can achieve this lofty objective of Artificial intelligence.

And while these principles have been there since the 1950s, it is only now that we have the adequate computing power to make them relevant to us, which is one of the reasons for the current rise.
We are at the beginning of a new era in how we will develop smarter systems in the future. Machine learning has the potential to impact every sector. And as web developers, we are lucky to have customers with experience in all of those sectors.

## Thankyouu


